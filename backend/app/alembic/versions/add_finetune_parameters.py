"""Add finetune parameters table

Revision ID: add_finetune_parameters
Revises: 1a31ce608336
Create Date: 2024-11-29 12:45:00.000000

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql
import sqlmodel.sql.sqltypes
import uuid

# revision identifiers, used by Alembic.
revision = 'add_finetune_parameters'
down_revision = '1a31ce608336'
branch_labels = None
depends_on = None

def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        'finetune_parameters',
        sa.Column('id', postgresql.UUID(as_uuid=True), nullable=False),
        sa.Column('user_id', postgresql.UUID(as_uuid=True), nullable=False),
        sa.Column('name', sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column('description', sqlmodel.sql.sqltypes.AutoString(), nullable=True),
        sa.Column('created_at', sa.DateTime(), nullable=False),
        sa.Column('updated_at', sa.DateTime(), nullable=False),
        
        # 基础参数
        sa.Column('model_name', sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column('dataset_name', sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column('finetune_method', sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column('training_phase', sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column('checkpoint_path', sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        
        # 量化参数
        sa.Column('quantization_method', sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column('quantization_bits', sa.Integer(), nullable=False),
        sa.Column('prompt_template', sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        
        # 加速器参数
        sa.Column('accelerator_type', sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column('rope_interpolation_type', sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        
        # 优化器参数
        sa.Column('learning_rate', sa.Float(), nullable=False),
        sa.Column('weight_decay', sa.Float(), nullable=False),
        sa.Column('betas', sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column('compute_dtype', sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column('num_epochs', sa.Integer(), nullable=False),
        sa.Column('batch_size', sa.Integer(), nullable=False),
        
        # LoRA参数
        sa.Column('lora_alpha', sa.Integer(), nullable=False),
        sa.Column('lora_r', sa.Integer(), nullable=False),
        sa.Column('scaling_factor', sa.Float(), nullable=False),
        sa.Column('learing_rate_ratio', sa.Float(), nullable=False),
        sa.Column('lora_dropout', sa.Float(), nullable=False),
        sa.Column('is_create_new_adapter', sa.Boolean(), nullable=False),
        sa.Column('is_rls_lora', sa.Boolean(), nullable=False),
        sa.Column('is_do_lora', sa.Boolean(), nullable=False),
        sa.Column('is_pissa', sa.Boolean(), nullable=False),
        sa.Column('lora_target_modules', sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        
        sa.PrimaryKeyConstraint('id'),
        sa.ForeignKeyConstraint(['user_id'], ['user.id'], ondelete='CASCADE'),
    )
    # ### end Alembic commands ###

def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('finetune_parameters')
    # ### end Alembic commands ### 